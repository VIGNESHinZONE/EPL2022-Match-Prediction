{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dd185e-e755-42bf-8c48-4cb14d978aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Modelling\n",
    "\n",
    "After having thoroughly explored the dataset and building multiple simple baseline models using the Probability scores or Point Difference or Form Difference, we were able to achieve an approx 72%. Any ML we perform should perform better than our Baseline models. We will be exploring different ML algorithms to build this strategy.\n",
    "\n",
    "\n",
    "## Important Features\n",
    "\n",
    "Upon performing EDA, we have identified a few essential features that could determine the game's outcome. They are listed below - \n",
    "\n",
    "1. Winning Probabilities from different Betting Houses - \n",
    "    - Just on building a simple comparison model, we were able to generate 72% accuracy.\n",
    "    - We will also look at the difference between Opening and Closing Bets of various houses.\n",
    "    \n",
    "2. Point difference\n",
    "    - It measures the difference in point gained by the teams through the season. The baseline created using point difference gave us a 70% accuracy.\n",
    "    \n",
    "3. Form Difference\n",
    "    - We have built a custom formula to measure the current form of a team, which was discussed in `2. Analysis-v2 (Team Performance).ipynb`. Just using this formula, we were able to achieve 70 to 72% accuracy.\n",
    "    \n",
    "4. Elite Teams\n",
    "    - Let's create a unique feature to indicate that a Team is Elite. It has been observed that Betting Probabilities have a hard time predicting when Elite Teams are playing away. Elite Teams are - {'Man United', 'Chelsea', 'Tottenham', 'Liverpool', 'Man City', 'Arsenal'}\n",
    "    \n",
    "5. New Teams of Season\n",
    "    - Every season, the bottom three teams get relegated to a lower division, and three new teams from the lower division are included. These teams tend to be weaker playing sides. New Teams are - {'Norwich', 'Watford', 'Brentford'}\n",
    "\n",
    "\n",
    "## Cross-Validation\n",
    "\n",
    "It was observed that our Baseline model's performance was a bit weaker in the half of the tournament. So to effectively model our system, we adopted two validation strategies -\n",
    "\n",
    "1. We train a model on the first 30 weeks of the dataset and validate its performance on the last 8 weeks.\n",
    "2. We Randomly sample 80% of our dataset for the Train set and the rest of the 20% for validation. We might also experiment with K-fold random splitting as well\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "For the task, we need to successfully predict if the Away team has won the game or not. Since we do not know how detrimental a False Positive or False Negative could be, both Recall & Precision are essential. Here is the list of metrics we will note to evaluate the performance of our ML model - \n",
    "\n",
    "1. Recall\n",
    "2. Precision\n",
    "3. Accuracy\n",
    "4. ROC AUC score\n",
    "5. Confusion Matrix\n",
    "\n",
    "## Features Neglected or will be Later explored\n",
    "\n",
    "1. We have decided not to use the Asian Handicap Betting Odds as there seems to be a slight confusion. The resources I had read online mentioned that a small penalty value gets added to the final score. But the key value descriptions do not provide information about the type of Asian handicap being used. Hence, I have decided to move forward with things that I already know.\n",
    "\n",
    "2. We would like to later explore the effect of Total Goals and its betting odds on the outcome of the game.\n",
    "\n",
    "3. We would like to explore the effect of information about the Day of the week and the week when the game was played.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4aaca2-ab8b-451a-b79f-64aaf893ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "    build_ongoing_points_table, find_optimal_threshold,\n",
    "    generate_betting_probablity\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, recall_score, precision_score, \n",
    "    accuracy_score, roc_auc_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "random.seed(211)\n",
    "np.random.seed(211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d5801f-fff5-4743-8a31-0d7feed66dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset (366, 106)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>...</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/2021</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Brentford</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/08/2021</td>\n",
       "      <td>12:30</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/08/2021</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/08/2021</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>14/08/2021</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Div        Date   Time    HomeTeam        AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0  E0  13/08/2021  20:00   Brentford         Arsenal     2     0   H     1   \n",
       "1  E0  14/08/2021  12:30  Man United           Leeds     5     1   H     1   \n",
       "2  E0  14/08/2021  15:00     Burnley        Brighton     1     2   A     1   \n",
       "3  E0  14/08/2021  15:00     Chelsea  Crystal Palace     3     0   H     2   \n",
       "4  E0  14/08/2021  15:00     Everton     Southampton     3     1   H     0   \n",
       "\n",
       "   HTAG  ... AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  \\\n",
       "0     0  ...     1.62  0.50      1.75      2.05   1.81   2.13     2.05   \n",
       "1     0  ...     2.25 -1.00      2.05      1.75   2.17   1.77     2.19   \n",
       "2     0  ...     1.62  0.25      1.79      2.15   1.81   2.14     1.82   \n",
       "3     0  ...     1.94 -1.50      2.05      1.75   2.12   1.81     2.16   \n",
       "4     1  ...     1.67 -0.50      2.05      1.88   2.05   1.88     2.08   \n",
       "\n",
       "   MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0     2.17     1.80     2.09  \n",
       "1     1.93     2.10     1.79  \n",
       "2     2.19     1.79     2.12  \n",
       "3     1.93     2.06     1.82  \n",
       "4     1.90     2.03     1.86  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_df = pd.read_csv('E0.csv')\n",
    "print(f\"Shape of dataset {ori_df.shape}\")\n",
    "ori_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a8610-a2aa-4dac-878c-b372caa95457",
   "metadata": {},
   "source": [
    "# Target Variable and Time Stamping\n",
    "\n",
    "As per the goal of the project, we need to predict succesfully if the Away team can win or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b6a061-df88-435e-9302-1814fa1e39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Target\n",
    "ori_df['Result'] = (ori_df['FTR'] == 'A').astype(int)\n",
    "\n",
    "# Adding TimeStamp and Week No.\n",
    "ori_df['Datetime'] = ori_df['Date'] + \" \" + ori_df['Time']+\":00\"\n",
    "ori_df['Datetime'] = pd.to_datetime(ori_df['Datetime'], infer_datetime_format=True)\n",
    "min_date = ori_df['Datetime'].min()\n",
    "ori_df['Week No.'] = ori_df['Datetime'].apply(lambda x: int((x - min_date).days / 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec39d1e-cc01-4e8f-b575-e0bcef98a999",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Features Generation\n",
    "\n",
    "As discussed above, we will be generating all the important features that we will be using for building our machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992f3d42-b237-4bb7-9e8b-7e8055f6de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_houses_original_arg = {\n",
    "    'Bet365': ['B365H', 'B365D', 'B365A'],\n",
    "    'Bet&Win': ['BWH', 'BWD', 'BWA'],\n",
    "    'Interwetten': ['IWH', 'IWD', 'IWA'],\n",
    "    'Pinnacle': ['PSH', 'PSD', 'PSA'],\n",
    "    'VC Bet': ['VCH', 'VCD', 'VCA'],\n",
    "    'William Hill': ['WHH', 'WHD', 'WHA'],\n",
    "    'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "    'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "}\n",
    "\n",
    "betting_houses_closing_original_arg = {\n",
    "    'Bet365': ['B365CH', 'B365CD', 'B365CA'],\n",
    "    'Bet&Win': ['BWCH', 'BWCD', 'BWCA'],\n",
    "    'Interwetten': ['IWCH', 'IWCD', 'IWCA'],\n",
    "    'Pinnacle': ['PSCH', 'PSCD', 'PSCA'],\n",
    "    'VC Bet': ['VCCH', 'VCCD', 'VCCA'],\n",
    "    'William Hill': ['WHCH', 'WHCD', 'WHCA'],\n",
    "    'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "    'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "}\n",
    "\n",
    "elite_teams_original_arg = [\n",
    "    'Man United', 'Chelsea', 'Tottenham', 'Liverpool', 'Man City', 'Arsenal'\n",
    "]\n",
    "\n",
    "new_teams_original_arg = [\n",
    "    'Norwich', 'Watford', 'Brentford'\n",
    "]\n",
    "team_names_original_arg = ori_df['HomeTeam'].unique().tolist()\n",
    "performance_feat_names_original_arg = [\n",
    "    'Point Diff', 'Form Diff 1', 'Form Diff 2'\n",
    "]\n",
    "\n",
    "past_record_feat_original_arg = ['Elite Home', 'Elite Away', 'New Team Home', 'New Team Away']\n",
    "\n",
    "def build_features(\n",
    "    arg_df, \n",
    "    betting_houses = betting_houses_original_arg, \n",
    "    betting_houses_closing = betting_houses_closing_original_arg,\n",
    "    only_away = False,\n",
    "    all_teams = team_names_original_arg,\n",
    "    elite_teams = elite_teams_original_arg, \n",
    "    new_teams = new_teams_original_arg,\n",
    "    performance_feat_names = performance_feat_names_original_arg,\n",
    "    past_record_feat_names = past_record_feat_original_arg,\n",
    "    filter_names = None\n",
    "    ):\n",
    "    \n",
    "    arg_df = generate_betting_probablity(arg_df, betting_houses, betting_houses_closing)\n",
    "    arg_df = build_ongoing_points_table(arg_df, all_teams, elite_teams)\n",
    "    arg_df['Point Diff'] = arg_df['AwayPoint'] - arg_df['HomePoint']\n",
    "    arg_df['Form Diff 1'] = arg_df['AwayForm1'] - arg_df['HomeForm1']\n",
    "    arg_df['Form Diff 2'] = arg_df['AwayForm2'] - arg_df['HomeForm2']\n",
    "    arg_df['Elite Home'] = arg_df['HomeTeam'].apply(lambda x: 1 if x in elite_teams else 0)\n",
    "    arg_df['Elite Away'] = arg_df['AwayTeam'].apply(lambda x: 1 if x in elite_teams else 0)\n",
    "    arg_df['New Team Home'] = arg_df['HomeTeam'].apply(lambda x: 1 if x in new_teams else 0)\n",
    "    arg_df['New Team Away'] = arg_df['AwayTeam'].apply(lambda x: 1 if x in new_teams else 0)\n",
    "    \n",
    "    feature_names = []\n",
    "    if only_away:\n",
    "        feature_names += [betting_houses[k][2] + ' Prob' for k in betting_houses]\n",
    "        feature_names += [betting_houses_closing[k][2] + ' Prob' for k in betting_houses_closing]\n",
    "    else:\n",
    "        feature_names += [code + ' Prob' for k in betting_houses for code in betting_houses[k]]\n",
    "        feature_names += [code + ' Prob' for k in betting_houses_closing for code in betting_houses_closing[k]]\n",
    "    feature_names += performance_feat_names\n",
    "    feature_names += past_record_feat_names\n",
    "    feature_names += ['Result']\n",
    "    arg_df = arg_df[feature_names]\n",
    "    if filter_names is None:\n",
    "        return arg_df\n",
    "    else:\n",
    "        return arg_df[filter_names + ['Result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd5c32-53a8-46a2-9695-e1301f856df8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Validation Methods\n",
    "\n",
    "We will implement our two main stratergies to validate our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01585592-31c6-4ed5-947f-b21fdfeec65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split_by_dates(arg_df, ori_df, threshold_week = 30):\n",
    "    train_len, *_ = ori_df[ori_df['Week No.'] <= threshold_week]['Week No.'].shape\n",
    "    train_df = arg_df.iloc[:train_len]\n",
    "    val_df = arg_df.iloc[train_len:]\n",
    "    y_train = train_df['Result'].to_numpy()\n",
    "    train_df = train_df.drop(['Result'], axis=1)\n",
    "    X_train = train_df.to_numpy()\n",
    "\n",
    "    y_test = val_df['Result'].to_numpy()\n",
    "    val_df = val_df.drop(['Result'], axis=1)\n",
    "    X_test = val_df.to_numpy()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def cross_validation_random_sample(arg_df, split_ratio=0.2, seed = 211):\n",
    "    Y = arg_df['Result'].to_numpy()\n",
    "    arg_df = arg_df.drop(['Result'], axis=1)\n",
    "    X = arg_df.to_numpy()\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, Y, test_size=split_ratio, random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def k_fold_cross_validation(arg_df, folds = 5, seed=211):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    y = arg_df['Result'].to_numpy()\n",
    "    arg_df = arg_df.drop(['Result'], axis=1)\n",
    "    X = arg_df.to_numpy()\n",
    "    datasets = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        datasets.append((X_train, X_test, y_train, y_test))\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1daf1c-5101-40ff-aff2-ef91cf47b0c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaulation Metrics\n",
    "\n",
    "Lets include a function to calculate all the metrics needed for task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30c9385-ee1e-454b-9756-0032b54d2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_pred, y_true, threshold = 0.5):\n",
    "    roc_auc = None\n",
    "    if threshold is not None:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        y_pred = y_pred > threshold\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    if threshold is not None:\n",
    "        return accuracy, precision, recall, roc_auc\n",
    "    else:\n",
    "        return accuracy, precision, recall\n",
    "    # print(\"Evaulation Report\\n\")\n",
    "\n",
    "    # print(f\"Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f} \")\n",
    "    # print(f\"AUC Score={roc_auc:.4f} \\n\")\n",
    "    # print(\"Confusion Matrix\\n\")\n",
    "    # print(\"         | Predicted 0 | Predicted 1\")\n",
    "    # print(f\"Actual 0 | {tn:11} | {fp:11}\")\n",
    "    # print(f\"Actual 1 | {fn:11} | {tp:11}\")\n",
    "    # print(\"\\n\")\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c513eea-0a29-4efb-8e3b-010150c04904",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d145e0d-6cfa-4463-876d-1d4ecb1a4a7f",
   "metadata": {},
   "source": [
    "Lets build essential functions for training the ML model. It will include features to where any Model following the Scikit-Learn API will be accepted,choose the important features and include SMOTE sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ca33d2-7db5-4a3d-8aca-a01e631ebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, filter_names = None, SMOTE_apply = False):\n",
    "\n",
    "    feat_df = build_features(ori_df, betting_houses_arg, betting_houses_closing_arg, filter_names = filter_names)\n",
    "    sm = SMOTE(random_state=211)\n",
    "    print(\"Time Based Cross Validation - \")\n",
    "    X_train, X_test, y_train, y_test = cross_validation_split_by_dates(feat_df, ori_df)\n",
    "    if SMOTE_apply:\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    acc, pre, rec, roc_auc = evaluate_performance(y_pred, y_test)\n",
    "    print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f}, AUC={roc_auc:.3f} \\n\")\n",
    "    \n",
    "    print(\"K fold Cross Validation - \")\n",
    "    datasets = k_fold_cross_validation(feat_df)\n",
    "    avg_acc, avg_pre, avg_rec, avg_auc = 0, 0, 0, 0 \n",
    "    folds = 5\n",
    "    datasets = k_fold_cross_validation(feat_df, folds=folds)\n",
    "\n",
    "    for data in datasets:\n",
    "        X_train, X_test, y_train, y_test = data\n",
    "        if SMOTE_apply:\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict_proba(X_test)[:,1]\n",
    "        acc, pre, rec, roc_auc = evaluate_performance(y_pred, y_test)\n",
    "        avg_acc += acc\n",
    "        avg_pre += pre\n",
    "        avg_rec += rec\n",
    "        avg_auc += roc_auc\n",
    "    avg_acc /= folds\n",
    "    avg_pre /= folds\n",
    "    avg_rec /= folds\n",
    "    avg_auc /= folds\n",
    "    print(f\"Accuracy={avg_acc:.3f}, Precison={avg_pre:.3f}, Recall={avg_rec:.3f}, AUC={avg_auc:.3f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746464c8-268c-4259-a79f-96e711e4c137",
   "metadata": {},
   "source": [
    "Before we procede, lets just list out the performance our Baseline models on the validation dataset taken in the last 8 weeks. We seem to achieve highest accuracy with Closing Odds Probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70237728-a573-44f8-97e5-79ed8e9192e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from Average Betting House\n",
      "Accuracy=0.695, Precison=0.695, Recall=0.615 \n",
      "\n",
      "Results from Maximum Betting House\n",
      "Accuracy=0.695, Precison=0.695, Recall=0.615 \n",
      "\n",
      "Results from Average Closing Betting House\n",
      "Accuracy=0.720, Precison=0.720, Recall=0.615 \n",
      "\n",
      "Results from Maximum Closing Betting House\n",
      "Accuracy=0.720, Precison=0.720, Recall=0.615 \n",
      "\n",
      "Results from Point Difference\n",
      "Accuracy=0.671, Precison=0.671, Recall=0.692 \n",
      "\n",
      "Results from Form Difference 1\n",
      "Accuracy=0.707, Precison=0.707, Recall=0.538 \n",
      "\n",
      "Results from Form Difference 2\n",
      "Accuracy=0.671, Precison=0.671, Recall=0.654 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "betting_houses_arg = {\n",
    "    'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "    'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "}\n",
    "betting_houses_closing_arg = {\n",
    "    'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "    'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "}\n",
    "baseline_df = build_features(ori_df, betting_houses_arg, betting_houses_closing_arg)\n",
    "train_len, *_ = ori_df[ori_df['Week No.'] <= 30]['Week No.'].shape\n",
    "baseline_df = baseline_df.iloc[train_len:]\n",
    "\n",
    "for houses in betting_houses_arg:\n",
    "    codes = betting_houses_arg[houses]\n",
    "    y_pred = ((baseline_df[codes[2] + ' Prob'] > baseline_df[codes[0] + ' Prob']) & (baseline_df[codes[2] + ' Prob'] > baseline_df[codes[1] + ' Prob'])).astype(int)\n",
    "    y_true = baseline_df['Result']\n",
    "    print(f\"Results from {houses} Betting House\")\n",
    "    acc, pre, rec = evaluate_performance(y_pred, y_true, None)\n",
    "    print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f} \\n\")\n",
    "\n",
    "for houses in betting_houses_closing_arg:\n",
    "    codes = betting_houses_closing_arg[houses]\n",
    "    y_pred = ((baseline_df[codes[2] + ' Prob'] > baseline_df[codes[0] + ' Prob']) & (baseline_df[codes[2] + ' Prob'] > baseline_df[codes[1] + ' Prob'])).astype(int)\n",
    "    y_true = baseline_df['Result']\n",
    "    print(f\"Results from {houses} Closing Betting House\")\n",
    "    acc, pre, rec = evaluate_performance(y_pred, y_true, None)\n",
    "    print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f} \\n\")\n",
    "\n",
    "y_pred = (baseline_df['Point Diff'] > 4).astype(int)\n",
    "y_true = baseline_df['Result']\n",
    "print(f\"Results from Point Difference\")\n",
    "acc, pre, rec = evaluate_performance(y_pred, y_true, None)\n",
    "print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f} \\n\")\n",
    "\n",
    "y_pred = (baseline_df['Form Diff 1'] > 1.0).astype(int)\n",
    "y_true = baseline_df['Result']\n",
    "print(f\"Results from Form Difference 1\")\n",
    "acc, pre, rec = evaluate_performance(y_pred, y_true, None)\n",
    "print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f} \\n\")\n",
    "\n",
    "y_pred = (baseline_df['Form Diff 2'] > 3.0).astype(int)\n",
    "y_true = baseline_df['Result']\n",
    "print(f\"Results from Form Difference 2\")\n",
    "acc, pre, rec = evaluate_performance(y_pred, y_true, None)\n",
    "print(f\"Accuracy={acc:.3f}, Precison={acc:.3f}, Recall={rec:.3f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811a8b3-b46b-471b-b321-c15c18398e65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "After careful exploration, I had chosen LogisticRegression & XGBoost as they seemed to Consistently give better results.\n",
    "\n",
    "In our first case, we achieved (70% accuracy, 65% Precison and 36% recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc8d790c-319d-44a5-8826-f88c4676e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without SMOTE Sampling: \n",
      "\n",
      "Time Based Cross Validation - \n",
      "Accuracy=0.707, Precison=0.707, Recall=0.577, AUC=0.689 \n",
      "\n",
      "K fold Cross Validation - \n",
      "Accuracy=0.713, Precison=0.651, Recall=0.360, AUC=0.687 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "betting_houses_arg = {\n",
    "    'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "    'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "}\n",
    "betting_houses_closing_arg = {\n",
    "    'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "    'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "}\n",
    "clf = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='liblinear',\n",
    "    C=0.1\n",
    ")\n",
    "print(\"Without SMOTE Sampling: \\n\")\n",
    "model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = False)\n",
    "\n",
    "# print(\"With SMOTE Analysis:\")\n",
    "# model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "249a0dfc-74b9-4620-8dc2-73fc991ae4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# betting_houses_arg = {\n",
    "#     'Bet365': ['B365H', 'B365D', 'B365A'],\n",
    "#     'Bet&Win': ['BWH', 'BWD', 'BWA'],\n",
    "#     'Pinnacle': ['PSH', 'PSD', 'PSA'],\n",
    "#     'VC Bet': ['VCH', 'VCD', 'VCA'],\n",
    "#     'William Hill': ['WHH', 'WHD', 'WHA'],\n",
    "#     'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "#     'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "\n",
    "# }\n",
    "# betting_houses_closing_arg = {\n",
    "#     'Bet365': ['B365CH', 'B365CD', 'B365CA'],\n",
    "#     'Bet&Win': ['BWCH', 'BWCD', 'BWCA'],\n",
    "#     'Pinnacle': ['PSCH', 'PSCD', 'PSCA'],\n",
    "#     'VC Bet': ['VCCH', 'VCCD', 'VCCA'],\n",
    "#     'William Hill': ['WHCH', 'WHCD', 'WHCA'],\n",
    "#     'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "#     'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "\n",
    "# }\n",
    "# filter_names = [betting_houses_arg[k][2]+ ' Prob' for k in betting_houses_arg]\n",
    "# clf = LogisticRegression(\n",
    "#     penalty='l1',\n",
    "#     solver='liblinear',\n",
    "#     C=0.1\n",
    "# )\n",
    "# print(\"Without SMOTE Sampling: \\n\")\n",
    "# model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, filter_names, SMOTE_apply = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf342b3-b1c1-4a52-9672-1ed4b8907133",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The XGBoost classifier trained from SMOTE smapling seems to be performing very well on the Week Based Cross Validation dataset with 73% accuracy, 73% precison and 69% recall. Its performance is slightly below average in the random sampling scenario with 67% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44898d02-bcd0-4b91-aa40-05be98e22940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without SMOTE Sampling: \n",
      "\n",
      "Time Based Cross Validation - \n",
      "Accuracy=0.695, Precison=0.695, Recall=0.577, AUC=0.663 \n",
      "\n",
      "K fold Cross Validation - \n",
      "Accuracy=0.680, Precison=0.548, Recall=0.464, AUC=0.715 \n",
      "\n",
      "With SMOTE Analysis:\n",
      "Time Based Cross Validation - \n",
      "Accuracy=0.732, Precison=0.732, Recall=0.692, AUC=0.714 \n",
      "\n",
      "K fold Cross Validation - \n",
      "Accuracy=0.669, Precison=0.515, Recall=0.576, AUC=0.703 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "betting_houses_arg = {\n",
    "    'Bet365': ['B365H', 'B365D', 'B365A'],\n",
    "    'Bet&Win': ['BWH', 'BWD', 'BWA'],\n",
    "    'Pinnacle': ['PSH', 'PSD', 'PSA'],\n",
    "    'VC Bet': ['VCH', 'VCD', 'VCA'],\n",
    "    'William Hill': ['WHH', 'WHD', 'WHA'],\n",
    "    'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "    'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "\n",
    "}\n",
    "betting_houses_closing_arg = {\n",
    "    'Bet365': ['B365CH', 'B365CD', 'B365CA'],\n",
    "    'Bet&Win': ['BWCH', 'BWCD', 'BWCA'],\n",
    "    'Pinnacle': ['PSCH', 'PSCD', 'PSCA'],\n",
    "    'VC Bet': ['VCCH', 'VCCD', 'VCCA'],\n",
    "    'William Hill': ['WHCH', 'WHCD', 'WHCA'],\n",
    "    'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "    'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "\n",
    "}\n",
    "clf = XGBClassifier(\n",
    "    max_depth=2,\n",
    "    gamma=2,\n",
    "    eta=0.8,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=0.5\n",
    ")\n",
    "print(\"Without SMOTE Sampling: \\n\")\n",
    "model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = False)\n",
    "\n",
    "print(\"With SMOTE Analysis:\")\n",
    "model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fa281-2b67-418f-b4da-edea12aef7d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We also wanted to explore the possibility of Ensembling the results of XGboost & Logistic Regression. But we did not recieve a very high accuracy performance. The time based cross validation performed well on SMOTE sampling and k-fold cross validation performed better without SMOTE sampling by achieving a 0.712 AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7d23ed-700f-4538-b916-08019444c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without SMOTE Sampling: \n",
      "\n",
      "Time Based Cross Validation - \n",
      "Accuracy=0.671, Precison=0.671, Recall=0.538, AUC=0.648 \n",
      "\n",
      "K fold Cross Validation - \n",
      "Accuracy=0.683, Precison=0.549, Recall=0.480, AUC=0.712 \n",
      "\n",
      "With SMOTE Analysis:\n",
      "Time Based Cross Validation - \n",
      "Accuracy=0.707, Precison=0.707, Recall=0.692, AUC=0.716 \n",
      "\n",
      "K fold Cross Validation - \n",
      "Accuracy=0.669, Precison=0.515, Recall=0.552, AUC=0.697 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "betting_houses_arg = {\n",
    "    'Bet365': ['B365H', 'B365D', 'B365A'],\n",
    "    'Bet&Win': ['BWH', 'BWD', 'BWA'],\n",
    "    'Pinnacle': ['PSH', 'PSD', 'PSA'],\n",
    "    'VC Bet': ['VCH', 'VCD', 'VCA'],\n",
    "    'William Hill': ['WHH', 'WHD', 'WHA'],\n",
    "    'Average': ['AvgH', 'AvgD', 'AvgA'],\n",
    "    'Maximum': ['MaxH', 'MaxD', 'MaxA']\n",
    "\n",
    "}\n",
    "betting_houses_closing_arg = {\n",
    "    'Bet365': ['B365CH', 'B365CD', 'B365CA'],\n",
    "    'Bet&Win': ['BWCH', 'BWCD', 'BWCA'],\n",
    "    'Pinnacle': ['PSCH', 'PSCD', 'PSCA'],\n",
    "    'VC Bet': ['VCCH', 'VCCD', 'VCCA'],\n",
    "    'William Hill': ['WHCH', 'WHCD', 'WHCA'],\n",
    "    'Average': ['AvgCH', 'AvgCD', 'AvgCA'],\n",
    "    'Maximum': ['MaxCH', 'MaxCD', 'MaxCA']\n",
    "\n",
    "}\n",
    "clf = StackingClassifier(\n",
    "    classifiers=[\n",
    "        LogisticRegression(\n",
    "            penalty='l1',\n",
    "            solver='liblinear',\n",
    "            C=0.1\n",
    "        ),\n",
    "        XGBClassifier(\n",
    "            max_depth=2,\n",
    "            gamma=2,\n",
    "            eta=0.8,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=0.5\n",
    "        )\n",
    "    ],\n",
    "    use_probas=True,\n",
    "    meta_classifier=LogisticRegression()\n",
    ")\n",
    "print(\"Without SMOTE Sampling: \\n\")\n",
    "model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = False)\n",
    "\n",
    "print(\"With SMOTE Analysis:\")\n",
    "model_training_evaluation(clf, ori_df, betting_houses_arg, betting_houses_closing_arg, SMOTE_apply = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football",
   "language": "python",
   "name": "football"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
